# -*- coding: utf-8 -*-
"""prediction_script_local.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P_lKbzyZFrMzg00nyH5prGuMNxP9C3CI
"""

# ===============================
# PREDICTION SCRIPT - LOCAL UPLOAD VERSION
# ===============================

import pandas as pd
import numpy as np
import joblib
import os
import re
from sklearn.preprocessing import LabelEncoder, StandardScaler
from google.colab import files

# Step 1: Upload model and CSV locally
print("üìÅ Please upload your model (.joblib) and data (.csv) files:")
uploaded = files.upload()

# Get file names
model_filename = next((f for f in uploaded if f.endswith(".joblib")), None)
data_filename = next((f for f in uploaded if f.endswith(".csv")), None)

if model_filename is None or data_filename is None:
    raise FileNotFoundError("‚ùå Missing .joblib or .csv file. Please upload both.")

# Step 2: Load the model
print(f"\n‚úÖ Loading model from: {model_filename}")
model = joblib.load(model_filename)

# Step 3: Load and preprocess the data
def format_column_names(df):
    df.columns = [re.sub(r"\s+", "_", col.strip().lower()) for col in df.columns]
    return df

def encode_categorical_columns(df):
    df_encoded = df.copy()
    categorical_cols = df_encoded.select_dtypes(include=['object']).columns
    label_encoders = {}
    for col in categorical_cols:
        le = LabelEncoder()
        df_encoded[col] = le.fit_transform(df_encoded[col])
        label_encoders[col] = le
    return df_encoded

def preprocess_data(df):
    df = format_column_names(df)
    df_encoded = encode_categorical_columns(df)

    expected_columns = [
        'business_travel', 'department', 'education_field', 'gender', 'job_role',
        'marital_status', 'over_time', 'transform_age', 'transform_daily_rate',
        'transform_distance_from_home', 'transform_education', 'transform_environment_satisfaction',
        'transform_hourly_rate', 'transform_job_involvement', 'transform_job_level',
        'transform_job_satisfaction', 'transform_monthly_income', 'transform_monthly_rate',
        'transform_num_companies_worked', 'transform_percent_salary_hike',
        'transform_performance_rating', 'transform_relationship_satisfaction',
        'transform_stock_option_level', 'transform_total_working_years',
        'transform_training_times_last_year', 'transform_work_life_balance',
        'transform_years_at_company', 'transform_years_in_current_role',
        'transform_years_since_last_promotion', 'transform_years_with_curr_manager'
    ]

    # Create transform columns if the original columns exist
    for col in expected_columns:
        if col.startswith('transform_'):
            base_col = col.replace('transform_', '')
            if base_col in df_encoded.columns:
                scaler = StandardScaler()
                df_encoded[col] = scaler.fit_transform(df_encoded[[base_col]])

    # Drop any columns not in expected_columns
    for col in df_encoded.columns:
        if col not in expected_columns:
            df_encoded.drop(col, axis=1, inplace=True)

    # Fill any missing expected columns with 0 (placeholder)
    for col in expected_columns:
        if col not in df_encoded.columns:
            df_encoded[col] = 0

    df_final = df_encoded[expected_columns]
    return df_final, df_encoded

# Step 4: Load data and apply preprocessing
df_raw = pd.read_csv(data_filename)
df_final, df_encoded = preprocess_data(df_raw)

# Step 5: Predict
print("üîÆ Making predictions...")
clusters = model.predict(df_final)
df_result = df_encoded.copy()
df_result['employee_segment'] = clusters.astype(str)

# Step 6: Show and export result
print("\nüìä Prediction Sample:")
print(df_result[['employee_segment']].value_counts().reset_index(name='count'))

# Export results
output_filename = "prediction_results.csv"
df_result.to_csv(output_filename, index=False)
print(f"\n‚úÖ Prediction results saved as: {output_filename}")

# Offer download link
files.download(output_filename)